# ğŸ›£ï¸ Project ROADMAP: CrewAI-Based Local Assistant

## ğŸ§­ Core Philosophy & Goals

> **"Build an AI system that teaches CS through a useful, modular, and extensible project."**

- âš™ï¸ Use agentic workflows to mirror real-world system design
- ğŸ§  Teach coding, architecture, and AI via real project structure
- ğŸ” Run *entirely locally* using LM Studio or similar LLM host
- ğŸª Maintain prompt transparency, agent introspectability, and traceable memory

---

## âœ… Phase 0 â€“ Smoke Check & Ground Rules

- â˜‘ Platform selected: **CrewAI** (with optional LangGraph/MCP)
- â˜‘ SOPs written: snapshot tools, `.gitignore`, modular file structure
- â˜‘ Tech inventory documented (`TECH_STACK.md`)
- â˜‘ GitHub repo deployed: [`crew-assistant`](https://github.com/nocturnaltungsten/crew-assistant)

---

## ğŸ”§ Phase 1 â€“ Groundwork

### 1.1. Minimum Viable Crew
- â˜‘ `Commander`: human UX interface (chat, CLI, future GUI)
- â˜‘ `PlannerAgent`: breaks goals into subtasks
- â˜‘ `DevAgent`: executes subtasks and returns results
- â˜‘ Core context engine prototype functional

### 1.2. File Structure & Dev Ergonomics
- â˜‘ `/agents/`, `/tasks/`, `/core/`, `/snapshots/`
- â˜‘ `.gitignore` ignores local-only tools like `fetch_docs.py`
- â˜‘ Fish shell tools and snapshot automation in place

### 1.3. Docs & Knowledge Aggregator (Local)
- â˜‘ Manual fetch tool for scraping docs/READMEs into `/docs/`
- â³ Optional embed & search via LlamaIndex (future)

---

## ğŸ§  Phase 2 â€“ Context Engine & Memory Core

### 2.1. Core Memory Store (MVP)
- â˜‘ Input/output summaries stored to JSON file
- â˜‘ Logging agent, task, timestamp, prompt/output
- â³ Validate persistence across sessions
- â³ Add per-task summaries + agent metadata

### 2.2. Context Injection
- â³ Feed memory summaries into next agent prompt
- â³ Filter based on task relevance and agent

---

## ğŸ§± Phase 3 â€“ Modular Scalability Foundation

### 3.1. Inference Manager
- â³ Central gatekeeper controls LLM access
- â³ Priority system: `urgency * importance`
- â³ Light-weight model for UX agent = always first
- â³ Task queue with async inference routing

### 3.2. Agent/Team-Specific Memory
- â³ Add vector stores per agent/team
- â³ Knowledge scraping agents for docs, APIs, tools
- â³ Agents return relevance scores per chunk to improve search

### 3.3. Prompt Observability & Control
- â³ Agent config files in `/configs/agent_prompts/`
- â³ Template override & versioning
- â³ Logging of prompt + final output for audit/debug

---

## ğŸš€ Phase 4 â€“ Expansion & UX Polish

### 4.1. Multimodal Input
- â³ Audio, image, and file processing agents
- â³ Transcription (Whisper), vision (local CLIP, etc.)

### 4.2. Task Execution Agents
- â³ File I/O, subprocess, shell runners
- â³ Guardrails for safety (e.g. sandbox execution)

### 4.3. Interactive UX Layer
- â³ Web dashboard or `.app` GUI
- â³ Drag-and-drop .dmg installer
- â³ Real-time log viewer + memory browser

---

## ğŸ“¦ Phase 5 â€“ Template & Reusability

- â³ Split into reusable agentic assistant template repo
- â³ Add examples for other domains (data analysis, writing tutor)
- â³ Document for onboarding new devs/contributors

---

## ğŸ“Next Tasks

| Task | Status |
|------|--------|
| `.gitignore` cleanup | âœ… |
| Snapshot tooling | âœ… |
| Modular memory store | âœ… MVP |
| Prioritized inference manager | â³ |
| Agent memory router | â³ |
| Prompt config + override system | â³ |
| Feed memory into agents | â³ |

---

> ğŸ’¡ **Reminder**: This roadmap evolves. Each phase expands capabilities **without breaking ergonomics or stability.**

---

